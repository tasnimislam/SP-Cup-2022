{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: seaborn in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (0.11.2)\n","Requirement already satisfied: matplotlib>=2.2 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from seaborn) (3.5.1)\n","Requirement already satisfied: scipy>=1.0 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from seaborn) (1.8.0)\n","Requirement already satisfied: pandas>=0.23 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from seaborn) (1.4.2)\n","Requirement already satisfied: numpy>=1.15 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from seaborn) (1.21.6)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras in c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages (2.8.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\manami\\anaconda3\\envs\\roadcrack\\lib\\site-packages)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): ...working... done\n","Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n","\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING conda.core.index:push_record(267): Skipping pypi/pypi::bleach-5.0.0-pypi_0 due to InvalidSpec: 1.1.0<1.2\n","\n","InvalidVersionSpec: Invalid version '1.1.0<1.2': invalid character(s)\n","\n"]}],"source":["!pip install seaborn\n","# !pip install tensorflow-io\n","!pip install keras --upgrade\n","%conda install -c hesi_m keras"]},{"cell_type":"markdown","metadata":{},"source":["# setup"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:38.902463Z","iopub.status.busy":"2022-04-27T08:41:38.902166Z","iopub.status.idle":"2022-04-27T08:41:45.795217Z","shell.execute_reply":"2022-04-27T08:41:45.794304Z","shell.execute_reply.started":"2022-04-27T08:41:38.902381Z"},"trusted":true},"outputs":[],"source":["import os\n","import pathlib\n","import pickle\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","import tensorflow as tf\n","import librosa\n","import librosa.display\n","import pandas as pd\n","\n","import tensorflow.python.keras as keras\n","#import tensorflow_io as tfio\n","\n","from keras import layers\n","from keras import models\n","from IPython import display\n","from pathlib import Path\n","from IPython.display import Audio\n","from keras import utils\n","\n","from sklearn.model_selection import train_test_split\n","\n","\n","# Set the seed value for experiment reproducibility.\n","seed = 42\n","SR=16000 # resampling as the ram can't handle this much calculation\n","BATCH_SIZE = 10\n","AUD_LENGTH = 10#sec\n","tf.random.set_seed(seed)\n","np.random.seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["# generating a dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:45.799087Z","iopub.status.busy":"2022-04-27T08:41:45.798795Z","iopub.status.idle":"2022-04-27T08:41:46.397466Z","shell.execute_reply":"2022-04-27T08:41:46.396731Z","shell.execute_reply.started":"2022-04-27T08:41:45.799047Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Our class names: ['0', '1', '2', '3', '4', '5']\n","Processing speaker 0\n","Actual Label  0\n","Processing speaker 1\n","Actual Label  1\n","Processing speaker 2\n","Actual Label  2\n","Processing speaker 3\n","Actual Label  3\n","Processing speaker 4\n","Actual Label  4\n","Processing speaker 5\n","Actual Label  5\n","Found 10500 files belonging to 6 classes.\n"]}],"source":["# getting audio dataset path to divide into 3 datasets and also for making tf datasets later\n","\n","DATASET_AUDIO_PATH = 'classwise_final_2k_imtiaz/classwise_final_2k'\n","class_names = os.listdir(DATASET_AUDIO_PATH)\n","print(\"Our class names: {}\".format(class_names,))\n","\n","audio_paths = []\n","labels = []\n","for label, name in enumerate(class_names):\n","    label = int(name)\n","    print(\"Processing speaker {}\".format(name,))\n","    print(\"Actual Label \",label)\n","    dir_path = Path(DATASET_AUDIO_PATH) / name\n","    speaker_sample_paths = [\n","        os.path.join(dir_path, filepath)\n","        for filepath in os.listdir(dir_path)\n","        if filepath.endswith(\".wav\")\n","    ]\n","    audio_paths += speaker_sample_paths\n","    labels += [label] * len(speaker_sample_paths)\n","\n","print(\n","    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:46.398998Z","iopub.status.busy":"2022-04-27T08:41:46.398588Z","iopub.status.idle":"2022-04-27T08:41:46.412544Z","shell.execute_reply":"2022-04-27T08:41:46.411783Z","shell.execute_reply.started":"2022-04-27T08:41:46.398964Z"},"trusted":true},"outputs":[],"source":["X_train, X, y_train, y = train_test_split(audio_paths, labels, test_size=0.3, random_state=seed)\n","X_val,X_test,y_val,y_test = train_test_split(X,y, test_size=0.333333, random_state=seed)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:46.414629Z","iopub.status.busy":"2022-04-27T08:41:46.41438Z","iopub.status.idle":"2022-04-27T08:41:46.422509Z","shell.execute_reply":"2022-04-27T08:41:46.421627Z","shell.execute_reply.started":"2022-04-27T08:41:46.414586Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7350 7350\n","2100 2100\n","1050 1050\n"]}],"source":["print(len(X_train),len(y_train))\n","print(len(X_val),len(y_val))\n","print(len(X_test),len(y_test))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:46.424392Z","iopub.status.busy":"2022-04-27T08:41:46.424102Z","iopub.status.idle":"2022-04-27T08:41:46.432289Z","shell.execute_reply":"2022-04-27T08:41:46.431462Z","shell.execute_reply.started":"2022-04-27T08:41:46.424357Z"},"trusted":true},"outputs":[],"source":["# utility functions for repeating audio files\n","def repeated_data(file_path):\n","    \"\"\" This function will take a file path and give out truncated and padded to 10s version waveform\"\"\"\n","    y, sr = librosa.load(file_path,sr=SR)\n","    aud_length = AUD_LENGTH*sr # making all audio length 10 s and truncating the rest\n","    duration = librosa.get_duration(y=y, sr=sr)\n","    if duration < AUD_LENGTH:\n","        y = np.tile(y, int((aud_length/sr) // duration)+1)\n","    y = librosa.resample(y[:aud_length], orig_sr=sr, target_sr=SR)\n","    return y\n","\n","def repeated_dataset(dataset):\n","    \"\"\" This function generated waveshape dataset\"\"\"\n","    new_ds = []\n","    for f in dataset:\n","        new_ds.append(repeated_data(f))\n","    return new_ds"]},{"cell_type":"markdown","metadata":{},"source":["## datagenerator"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:46.43411Z","iopub.status.busy":"2022-04-27T08:41:46.433702Z","iopub.status.idle":"2022-04-27T08:41:46.447566Z","shell.execute_reply":"2022-04-27T08:41:46.446835Z","shell.execute_reply.started":"2022-04-27T08:41:46.43407Z"},"trusted":true},"outputs":[],"source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, labels, batch_size= BATCH_SIZE, \n","                 n_classes=6, shuffle=True):\n","        'Initialization'\n","        self.dim = AUD_LENGTH * SR\n","        self.batch_size = batch_size\n","        self.labels = labels\n","        self.shuffle = shuffle\n","        self.list_IDs = list_IDs\n","        self.on_epoch_end()\n","\n","    def path_to_audio(self,path):\n","        \"\"\"Reads and decodes an audio file.\"\"\"\n","        return repeated_data(path)\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Generate data\n","        X, y = self.__data_generation(indexes)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples'\n","        \n","        X = []\n","        y = []\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            _tempx = self.path_to_audio(self.list_IDs[ID])\n","            #_tempx = self.spect_audio(_tempx)\n","            X.append(_tempx)\n","\n","            # Store class\n","            y.append(self.labels[ID])\n","\n","        return np.reshape(np.array(X), (self.batch_size,SR*AUD_LENGTH,1)).astype(np.float32),np.array(y).astype(np.float32)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:46.449373Z","iopub.status.busy":"2022-04-27T08:41:46.448887Z","iopub.status.idle":"2022-04-27T08:41:46.462948Z","shell.execute_reply":"2022-04-27T08:41:46.460873Z","shell.execute_reply.started":"2022-04-27T08:41:46.449331Z"},"trusted":true},"outputs":[],"source":["# generating tf datasets\n","train_ds = DataGenerator(X_train,y_train)\n","\n","valid_ds = DataGenerator(X_val,y_val)\n","\n","test_ds = DataGenerator(X_test,y_test)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:46.464937Z","iopub.status.busy":"2022-04-27T08:41:46.464488Z","iopub.status.idle":"2022-04-27T08:41:49.62402Z","shell.execute_reply":"2022-04-27T08:41:49.623336Z","shell.execute_reply.started":"2022-04-27T08:41:46.464903Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input (InputLayer)             [(None, 160000, 1)]  0           []                               \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 160000, 16)   160         ['input[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 160000, 16)  64          ['conv1d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," re_lu (ReLU)                   (None, 160000, 16)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," max_pooling1d (MaxPooling1D)   (None, 40000, 16)    0           ['re_lu[0][0]']                  \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 40000, 32)    4640        ['max_pooling1d[0][0]']          \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 40000, 32)   128         ['conv1d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_1 (ReLU)                 (None, 40000, 32)    0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, 40000, 32)    7200        ['re_lu_1[0][0]']                \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 40000, 32)   128         ['conv1d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_2 (ReLU)                 (None, 40000, 32)    0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 40000, 32)    3104        ['re_lu_2[0][0]']                \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 40000, 32)   128         ['conv1d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_3 (ReLU)                 (None, 40000, 32)    0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 40000, 32)    1056        ['re_lu_3[0][0]']                \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 40000, 32)   128         ['conv1d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_4 (ReLU)                 (None, 40000, 32)    0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 160000, 32)   0           ['re_lu_1[0][0]',                \n","                                                                  're_lu_2[0][0]',                \n","                                                                  're_lu_3[0][0]',                \n","                                                                  're_lu_4[0][0]']                \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 160000, 32)  128         ['concatenate[0][0]']            \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_5 (ReLU)                 (None, 160000, 32)   0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," max_pooling1d_1 (MaxPooling1D)  (None, 40000, 32)   0           ['re_lu_5[0][0]']                \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 40000, 64)    18496       ['max_pooling1d_1[0][0]']        \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 40000, 64)   256         ['conv1d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_6 (ReLU)                 (None, 40000, 64)    0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, 40000, 64)    28736       ['re_lu_6[0][0]']                \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 40000, 64)   256         ['conv1d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_7 (ReLU)                 (None, 40000, 64)    0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, 40000, 64)    12352       ['re_lu_7[0][0]']                \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 40000, 64)   256         ['conv1d_7[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_8 (ReLU)                 (None, 40000, 64)    0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv1d_8 (Conv1D)              (None, 40000, 64)    4160        ['re_lu_8[0][0]']                \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 40000, 64)   256         ['conv1d_8[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_9 (ReLU)                 (None, 40000, 64)    0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 160000, 64)   0           ['re_lu_6[0][0]',                \n","                                                                  're_lu_7[0][0]',                \n","                                                                  're_lu_8[0][0]',                \n","                                                                  're_lu_9[0][0]']                \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 160000, 64)  256         ['concatenate_1[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_10 (ReLU)                (None, 160000, 64)   0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," max_pooling1d_2 (MaxPooling1D)  (None, 40000, 64)   0           ['re_lu_10[0][0]']               \n","                                                                                                  \n"," conv1d_9 (Conv1D)              (None, 40000, 128)   73856       ['max_pooling1d_2[0][0]']        \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 40000, 128)  512         ['conv1d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_11 (ReLU)                (None, 40000, 128)   0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," conv1d_10 (Conv1D)             (None, 40000, 128)   114816      ['re_lu_11[0][0]']               \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 40000, 128)  512         ['conv1d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_12 (ReLU)                (None, 40000, 128)   0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," conv1d_11 (Conv1D)             (None, 40000, 128)   49280       ['re_lu_12[0][0]']               \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 40000, 128)  512         ['conv1d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_13 (ReLU)                (None, 40000, 128)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," conv1d_12 (Conv1D)             (None, 40000, 128)   16512       ['re_lu_13[0][0]']               \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 40000, 128)  512         ['conv1d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_14 (ReLU)                (None, 40000, 128)   0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 160000, 128)  0           ['re_lu_11[0][0]',               \n","                                                                  're_lu_12[0][0]',               \n","                                                                  're_lu_13[0][0]',               \n","                                                                  're_lu_14[0][0]']               \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 160000, 128)  512        ['concatenate_2[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_15 (ReLU)                (None, 160000, 128)  0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," max_pooling1d_3 (MaxPooling1D)  (None, 40000, 128)  0           ['re_lu_15[0][0]']               \n","                                                                                                  \n"," conv1d_13 (Conv1D)             (None, 40000, 256)   295168      ['max_pooling1d_3[0][0]']        \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 40000, 256)  1024        ['conv1d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_16 (ReLU)                (None, 40000, 256)   0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv1d_14 (Conv1D)             (None, 40000, 256)   459008      ['re_lu_16[0][0]']               \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 40000, 256)  1024        ['conv1d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_17 (ReLU)                (None, 40000, 256)   0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv1d_15 (Conv1D)             (None, 40000, 256)   196864      ['re_lu_17[0][0]']               \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 40000, 256)  1024        ['conv1d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_18 (ReLU)                (None, 40000, 256)   0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," conv1d_16 (Conv1D)             (None, 40000, 256)   65792       ['re_lu_18[0][0]']               \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 40000, 256)  1024        ['conv1d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_19 (ReLU)                (None, 40000, 256)   0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," concatenate_3 (Concatenate)    (None, 160000, 256)  0           ['re_lu_16[0][0]',               \n","                                                                  're_lu_17[0][0]',               \n","                                                                  're_lu_18[0][0]',               \n","                                                                  're_lu_19[0][0]']               \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 160000, 256)  1024       ['concatenate_3[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_20 (ReLU)                (None, 160000, 256)  0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," max_pooling1d_4 (MaxPooling1D)  (None, 625, 256)    0           ['re_lu_20[0][0]']               \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 256)         0           ['max_pooling1d_4[0][0]']        \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," flatten (Flatten)              (None, 256)          0           ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dense (Dense)                  (None, 64)           16448       ['flatten[0][0]']                \n","                                                                                                  \n"," dense_1 (Dense)                (None, 32)           2080        ['dense[0][0]']                  \n","                                                                                                  \n"," dropout (Dropout)              (None, 32)           0           ['dense_1[0][0]']                \n","                                                                                                  \n"," output (Dense)                 (None, 6)            198         ['dropout[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,379,590\n","Trainable params: 1,374,758\n","Non-trainable params: 4,832\n","__________________________________________________________________________________________________\n"]}],"source":["def DilatedConvModule(xx, filters):\n","    \n","    xx1 = tf.keras.layers.Conv1D(filters, kernel_size = 9,dilation_rate=1, padding= \"same\")(xx)\n","    xx1 = tf.keras.layers.BatchNormalization()(xx1)\n","    xx1 = tf.keras.layers.ReLU()(xx1)\n","    \n","    xx2 = tf.keras.layers.Conv1D(filters, kernel_size = 7,dilation_rate=2, padding= \"same\")(xx1)\n","    xx2 = tf.keras.layers.BatchNormalization()(xx2)\n","    xx2 = tf.keras.layers.ReLU()(xx2)\n","    \n","    xx4 = tf.keras.layers.Conv1D(filters, kernel_size = 3,dilation_rate=4, padding= \"same\")(xx2)\n","    xx4 = tf.keras.layers.BatchNormalization()(xx4)\n","    xx4 = tf.keras.layers.ReLU()(xx4)\n","    \n","    xx8 = tf.keras.layers.Conv1D(filters, kernel_size = 1,dilation_rate=8, padding= \"same\")(xx4)\n","    xx8 = tf.keras.layers.BatchNormalization()(xx8)\n","    xx8 = tf.keras.layers.ReLU()(xx8)\n","    #concat\n","    yy = tf.keras.layers.Concatenate(axis=1)([xx1,xx2,xx4,xx8])\n","    yy = tf.keras.layers.BatchNormalization()(yy)\n","    yy = tf.keras.layers.ReLU()(yy)\n","    \n","    return yy\n","\n","def build_model(input_shape, num_classes):\n","    inputs = tf.keras.layers.Input(shape=input_shape, name=\"input\")\n","    x      = tf.keras.layers.Conv1D(16, kernel_size = 9,dilation_rate=1, padding= \"same\")(inputs)\n","    x      = tf.keras.layers.BatchNormalization()(x)\n","    x      = tf.keras.layers.ReLU()(x)\n","    x      = tf.keras.layers.MaxPool1D(pool_size = 4)(x)\n","    \n","    # stacked resnet modules\n","    # inc1\n","    x      = DilatedConvModule(x,32)\n","    x      = tf.keras.layers.MaxPool1D(pool_size = 4)(x)\n","    #x      = tf.keras.layers.Dropout(0.5)(x)\n","    # inc2\n","    x      = DilatedConvModule(x,64)\n","    x      = tf.keras.layers.MaxPool1D(pool_size = 4)(x)\n","    #x      = tf.keras.layers.Dropout(0.25)(x)\n","    # inc4\n","    x      = DilatedConvModule(x,128)\n","    x      = tf.keras.layers.MaxPool1D(pool_size = 4)(x)\n","   #x      = tf.keras.layers.Dropout(0.25)(x)\n","    # inc8\n","    x      = DilatedConvModule(x,256)\n","    x      = tf.keras.layers.MaxPool1D(pool_size =  x.shape[-1])(x)\n","    #x      = tf.keras.layers.Dropout(0.5)(x)\n","    \n","    x      = tf.keras.layers.GlobalAveragePooling1D()(x)\n","    \n","    x      = tf.keras.layers.Flatten()(x)\n","    x      = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n","    x      = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n","    x      = tf.keras.layers.Dropout(0.25)(x)\n","    \n","    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n","    \n","    return tf.keras.models.Model(inputs=inputs, outputs=outputs)\n","\n","\n","aud_length = 16000*AUD_LENGTH\n","\n","model = build_model((aud_length, 1), len(class_names))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:49.625652Z","iopub.status.busy":"2022-04-27T08:41:49.625391Z","iopub.status.idle":"2022-04-27T08:41:49.643167Z","shell.execute_reply":"2022-04-27T08:41:49.642459Z","shell.execute_reply.started":"2022-04-27T08:41:49.625615Z"},"trusted":true},"outputs":[],"source":["# configuring the run\n","# Compile the model using Adam's default learning rate\n","model.compile(\n","    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","\n","# Add callbacks:\n","# 'EarlyStopping' to stop training when the model is not enhancing anymore\n","# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n","weight_save_filename = \"weight_inception_classwise2k_cv.h5\"\n","\n","lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=1, mode='min', min_lr=1e-9)\n","earlystopping_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=10, mode='min', restore_best_weights=True)\n","mdlcheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    weight_save_filename, monitor=\"val_accuracy\", save_best_only=True,save_weights_only=True)"]},{"cell_type":"markdown","metadata":{},"source":["# training"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-27T08:41:49.646151Z","iopub.status.busy":"2022-04-27T08:41:49.645903Z","iopub.status.idle":"2022-04-27T08:42:12.046766Z","shell.execute_reply":"2022-04-27T08:42:12.044314Z","shell.execute_reply.started":"2022-04-27T08:41:49.64612Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------- > Fold 4 < ---------------\n","Epoch 1/50\n","840/840 [==============================] - 711s 835ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 37.9554 - val_accuracy: 0.8143 - lr: 0.0010\n","Epoch 2/50\n","840/840 [==============================] - 700s 834ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 44.2284 - val_accuracy: 0.7800 - lr: 0.0010\n","Epoch 3/50\n","840/840 [==============================] - 700s 834ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 24.5840 - val_accuracy: 0.8133 - lr: 0.0010\n","Epoch 4/50\n","840/840 [==============================] - 701s 835ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 24.4018 - val_accuracy: 0.8181 - lr: 0.0010\n","Epoch 5/50\n","840/840 [==============================] - 700s 833ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 41.8755 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 6/50\n","840/840 [==============================] - 699s 832ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 38.2949 - val_accuracy: 0.8195 - lr: 0.0010\n","Epoch 7/50\n","840/840 [==============================] - 693s 826ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 36.9617 - val_accuracy: 0.7686 - lr: 0.0010\n","Epoch 8/50\n","840/840 [==============================] - 694s 826ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 35.4984 - val_accuracy: 0.8210 - lr: 0.0010\n","Epoch 9/50\n","840/840 [==============================] - 694s 826ms/step - loss: 0.0347 - accuracy: 0.9883 - val_loss: 52.7636 - val_accuracy: 0.8100 - lr: 0.0010\n","Epoch 10/50\n","840/840 [==============================] - 694s 826ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 38.6700 - val_accuracy: 0.8195 - lr: 0.0010\n","Epoch 11/50\n","840/840 [==============================] - 694s 826ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 64.5051 - val_accuracy: 0.8090 - lr: 0.0010\n","Epoch 12/50\n","840/840 [==============================] - 694s 826ms/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 49.4549 - val_accuracy: 0.8129 - lr: 0.0010\n","Epoch 13/50\n","840/840 [==============================] - 694s 827ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 33.2984 - val_accuracy: 0.8186 - lr: 0.0010\n","Epoch 14/50\n","840/840 [==============================] - 682s 813ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 49.9462 - val_accuracy: 0.7705 - lr: 0.0010\n","Epoch 15/50\n","840/840 [==============================] - 980s 1s/step - loss: 0.0265 - accuracy: 0.9936 - val_loss: 47.5739 - val_accuracy: 0.7938 - lr: 0.0010\n","Epoch 16/50\n","840/840 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9961\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","840/840 [==============================] - 718s 854ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 39.6742 - val_accuracy: 0.8200 - lr: 0.0010\n","Epoch 17/50\n","840/840 [==============================] - 682s 812ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 43.6966 - val_accuracy: 0.8210 - lr: 5.0000e-04\n","Epoch 18/50\n","840/840 [==============================] - 681s 811ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 48.7496 - val_accuracy: 0.8210 - lr: 5.0000e-04\n","Epoch 19/50\n","840/840 [==============================] - 667s 794ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 46.3349 - val_accuracy: 0.8205 - lr: 5.0000e-04\n","Epoch 20/50\n","840/840 [==============================] - 696s 828ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 53.1263 - val_accuracy: 0.8190 - lr: 5.0000e-04\n","Epoch 21/50\n","840/840 [==============================] - 822s 978ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 46.8376 - val_accuracy: 0.8186 - lr: 5.0000e-04\n","Epoch 22/50\n","840/840 [==============================] - 799s 952ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 38.6645 - val_accuracy: 0.8210 - lr: 5.0000e-04\n","Epoch 23/50\n","840/840 [==============================] - 903s 1s/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 39.4603 - val_accuracy: 0.8200 - lr: 5.0000e-04\n","Epoch 24/50\n","840/840 [==============================] - 1031s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 46.3175 - val_accuracy: 0.8210 - lr: 5.0000e-04\n","Epoch 25/50\n","840/840 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9973\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","840/840 [==============================] - 897s 1s/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 46.7368 - val_accuracy: 0.8200 - lr: 5.0000e-04\n","Epoch 26/50\n","840/840 [==============================] - 809s 963ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 48.7894 - val_accuracy: 0.8205 - lr: 2.5000e-04\n","Epoch 27/50\n","840/840 [==============================] - 772s 919ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 50.3452 - val_accuracy: 0.8129 - lr: 2.5000e-04\n","Epoch 28/50\n","840/840 [==============================] - 736s 877ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 50.1820 - val_accuracy: 0.8210 - lr: 2.5000e-04\n","Epoch 29/50\n","840/840 [==============================] - 637s 759ms/step - loss: 5.2859e-04 - accuracy: 0.9999 - val_loss: 49.2366 - val_accuracy: 0.8210 - lr: 2.5000e-04\n","Epoch 30/50\n","840/840 [==============================] - 671s 799ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 50.9833 - val_accuracy: 0.8210 - lr: 2.5000e-04\n","210/210 [==============================] - 44s 211ms/step - loss: 53.1262 - accuracy: 0.8190\n",">0.819\n","--------------- > Fold 5 < ---------------\n","Epoch 1/50\n","840/840 [==============================] - 629s 742ms/step - loss: 0.2693 - accuracy: 0.9642 - val_loss: 0.0183 - val_accuracy: 0.9976 - lr: 0.0010\n","Epoch 2/50\n","840/840 [==============================] - 622s 740ms/step - loss: 0.0450 - accuracy: 0.9815 - val_loss: 0.1036 - val_accuracy: 0.9605 - lr: 0.0010\n","Epoch 3/50\n","840/840 [==============================] - 621s 740ms/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 0.0016 - val_accuracy: 0.9995 - lr: 0.0010\n","Epoch 4/50\n","840/840 [==============================] - 621s 739ms/step - loss: 0.0425 - accuracy: 0.9898 - val_loss: 0.0122 - val_accuracy: 0.9976 - lr: 0.0010\n","Epoch 5/50\n","840/840 [==============================] - 622s 740ms/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 0.0093 - val_accuracy: 0.9957 - lr: 0.0010\n","Epoch 6/50\n","840/840 [==============================] - 622s 740ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.0260 - val_accuracy: 0.9905 - lr: 0.0010\n","Epoch 7/50\n","840/840 [==============================] - 621s 740ms/step - loss: 0.0397 - accuracy: 0.9913 - val_loss: 0.2291 - val_accuracy: 0.9671 - lr: 0.0010\n","Epoch 8/50\n","840/840 [==============================] - 621s 739ms/step - loss: 0.0313 - accuracy: 0.9926 - val_loss: 0.1962 - val_accuracy: 0.9490 - lr: 0.0010\n","Epoch 9/50\n","840/840 [==============================] - 620s 739ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.0034 - val_accuracy: 0.9990 - lr: 0.0010\n","Epoch 10/50\n","840/840 [==============================] - 665s 791ms/step - loss: 0.0234 - accuracy: 0.9952 - val_loss: 1.7648 - val_accuracy: 0.8238 - lr: 0.0010\n","Epoch 11/50\n","840/840 [==============================] - 684s 814ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.0339 - val_accuracy: 0.9905 - lr: 0.0010\n","Epoch 12/50\n","840/840 [==============================] - 685s 816ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.0123 - val_accuracy: 0.9962 - lr: 0.0010\n","Epoch 13/50\n","840/840 [==============================] - 687s 818ms/step - loss: 0.0393 - accuracy: 0.9898 - val_loss: 0.0573 - val_accuracy: 0.9786 - lr: 0.0010\n","Epoch 14/50\n","840/840 [==============================] - 686s 817ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.1813 - val_accuracy: 0.9533 - lr: 0.0010\n","Epoch 15/50\n","840/840 [==============================] - 686s 816ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.3995 - val_accuracy: 0.8852 - lr: 0.0010\n","Epoch 16/50\n","840/840 [==============================] - 685s 816ms/step - loss: 0.0363 - accuracy: 0.9918 - val_loss: 0.0086 - val_accuracy: 0.9962 - lr: 0.0010\n","Epoch 17/50\n","840/840 [==============================] - 685s 816ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0069 - val_accuracy: 0.9981 - lr: 0.0010\n","Epoch 18/50\n","840/840 [==============================] - 685s 815ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.5916 - val_accuracy: 0.8890 - lr: 0.0010\n","Epoch 19/50\n","840/840 [==============================] - 683s 814ms/step - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.0052 - val_accuracy: 0.9981 - lr: 0.0010\n","Epoch 20/50\n","840/840 [==============================] - 687s 818ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0122 - val_accuracy: 0.9971 - lr: 0.0010\n","Epoch 21/50\n","840/840 [==============================] - 684s 815ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 0.0481 - val_accuracy: 0.9857 - lr: 0.0010\n","Epoch 22/50\n","840/840 [==============================] - 684s 814ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0291 - val_accuracy: 0.9929 - lr: 0.0010\n","Epoch 23/50\n","840/840 [==============================] - 683s 813ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0509 - val_accuracy: 0.9876 - lr: 0.0010\n","Epoch 24/50\n","840/840 [==============================] - 699s 832ms/step - loss: 0.0209 - accuracy: 0.9958 - val_loss: 0.0192 - val_accuracy: 0.9948 - lr: 0.0010\n","Epoch 25/50\n","840/840 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9969\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","840/840 [==============================] - 682s 812ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.7284 - val_accuracy: 0.8486 - lr: 0.0010\n","Epoch 26/50\n","840/840 [==============================] - 680s 809ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0102 - val_accuracy: 0.9981 - lr: 5.0000e-04\n","Epoch 27/50\n","840/840 [==============================] - 680s 809ms/step - loss: 5.5210e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9981 - lr: 5.0000e-04\n","Epoch 28/50\n","840/840 [==============================] - 680s 809ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0209 - val_accuracy: 0.9962 - lr: 5.0000e-04\n","Epoch 29/50\n","840/840 [==============================] - 680s 810ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0123 - val_accuracy: 0.9971 - lr: 5.0000e-04\n","Epoch 30/50\n","840/840 [==============================] - 680s 810ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0151 - val_accuracy: 0.9971 - lr: 5.0000e-04\n","Epoch 31/50\n","840/840 [==============================] - 699s 833ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.0186 - val_accuracy: 0.9971 - lr: 5.0000e-04\n","Epoch 32/50\n"," 37/840 [>.............................] - ETA: 10:22 - loss: 7.8847e-04 - accuracy: 1.0000"]}],"source":["from sklearn.model_selection import KFold\n","EPOCHS=50\n","NFOLDS=5\n","folds = KFold(n_splits=NFOLDS)\n","splits = folds.split(audio_paths, labels)\n","\n","def evaluate_model(X_train, X_val, y_train, y_val,j):\n","    \n","    train_ds = DataGenerator(X_train,y_train)\n","    valid_ds = DataGenerator(X_val,y_val)\n","    aud_length = AUD_LENGTH * SR\n","    model = build_model((aud_length, 1), len(class_names))\n","    #epochs = 1\n","    #batch_size = 50\n","    model.compile(\n","    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","    weight_save_filename = \"weight_inception_classwise2k_cv\"+str(j+3)+\"fold_.h5\"\n","    lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=1, mode='min', min_lr=1e-9)\n","    earlystopping_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=10, mode='min', restore_best_weights=True)\n","    mdlcheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(weight_save_filename, monitor=\"val_accuracy\", save_best_only=True,save_weights_only=True, save_freq='epoch')\n","    \n","    model.load_weights('weight_inception_classwise2k_cv2fold_.h5')\n","\n","    history = model.fit(\n","    train_ds,\n","    epochs=EPOCHS,\n","    validation_data=valid_ds,\n","    callbacks=[lr_reduce,earlystopping_cb, mdlcheckpoint_cb],)\n","\n","    \n","\n"," \n","    _, val_acc = model.evaluate(valid_ds, verbose = 1)\n","    model.load_weights(\"./\"+weight_save_filename) #\n","    model.save(\"model_inception_classwise2k_cv\"+str(j+4)+\"fold_.h5\")\n","    return model, val_acc\n","\n","fin_model = 1\n","cv_scores, model_history = list(), list()\n","train = audio_paths\n","targets = labels\n","for fold, (train_idx, val_idx) in enumerate(splits):\n","    X_train = []\n","    X_valid = []\n","    y_train = []\n","    y_valid = []\n","    for i in train_idx:\n","        X_train.append(train[i])\n","        y_train.append(targets[i])\n","    for j in val_idx:\n","        X_valid.append(train[j])\n","        y_valid.append(targets[j])\n","    #X_train, X_valid = train[], train[test_idx]\n","    #y_train, y_valid = targets[train_idx], targets[test_idx]\n","    print('-'*15, '>', f'Fold {fold+4}', '<', '-'*15)\n","    model, val_acc = evaluate_model(X_train, X_val, y_train, y_val,fold)\n","    print('>%.3f' % val_acc)\n","    cv_scores.append(val_acc)\n","    if val_acc == max(cv_scores):\n","        fin_model = model\n","    model_history.append(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:42:12.04778Z","iopub.status.idle":"2022-04-27T08:42:12.048731Z","shell.execute_reply":"2022-04-27T08:42:12.048504Z","shell.execute_reply.started":"2022-04-27T08:42:12.04848Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["def ensemble_predictions(members, testX,testy=1):\n","    yhats = [model.predict(testX) for model in members]\n","    yhats = np.array(yhats)\n","    # sum across ensemble members\n","    summed = np.sum(yhats, axis=0)\n","    # argmax across classes\n","    result = np.argmax(summed, axis=1)\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:42:12.050053Z","iopub.status.idle":"2022-04-27T08:42:12.050458Z","shell.execute_reply":"2022-04-27T08:42:12.050262Z","shell.execute_reply.started":"2022-04-27T08:42:12.05024Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["preds = ensemble_predictions(model_history, valid_ds)\n","preds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:42:12.051511Z","iopub.status.idle":"2022-04-27T08:42:12.052163Z","shell.execute_reply":"2022-04-27T08:42:12.051932Z","shell.execute_reply.started":"2022-04-27T08:42:12.051908Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["np.unique(preds) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:42:12.053603Z","iopub.status.idle":"2022-04-27T08:42:12.054073Z","shell.execute_reply":"2022-04-27T08:42:12.053849Z","shell.execute_reply.started":"2022-04-27T08:42:12.053824Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["preds = ensemble_predictions(model_history, test_ds)\n","preds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:42:12.055483Z","iopub.status.idle":"2022-04-27T08:42:12.055885Z","shell.execute_reply":"2022-04-27T08:42:12.055694Z","shell.execute_reply.started":"2022-04-27T08:42:12.055671Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["np.unique(preds) "]},{"cell_type":"markdown","metadata":{},"source":["# evaluation"]},{"cell_type":"markdown","metadata":{},"source":["## librispeech"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["eval_path ='../input/spcup2022-final-dataset/asv_libri_ds/asv_libri_ds/librispeech'\n","speaker_sample_paths = [\n","        os.path.join(eval_path, filepath)\n","        for filepath in os.listdir(eval_path)\n","        if filepath.endswith(\".wav\")\n","    ]\n","X_eval = []\n","X_eval += speaker_sample_paths\n","\n","print(\n","    \"Found {} files\".format(len(X_eval))\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["# making a column of names\n","import os\n","n = len(X_eval)\n","filenames = []\n","for i in range(n):\n","    f_name, f_ext = os.path.splitext(X_eval[i])\n","    filenames.append(os.path.basename(f_name)+f_ext)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["y_eval = [0]*len(X_eval)\n","print(len(X_eval),len(y_eval))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["eval_ds = DataGenerator(X_eval,y_eval,shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["pred_class = ensemble_predictions(model_history, eval_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["score_df = pd.DataFrame({'file':filenames,'pred_class':pred_class})\n","score_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["score_df.pred_class.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["# converting dataframe to csv\n","score_df.to_csv('inceptionnetcv_2k_librispeech.csv', header=False, index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## asvspoof"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["eval_path ='../input/spcup2022-final-dataset/asv_libri_ds/asv_libri_ds/asvspoof/wav' \n","speaker_sample_paths = [ os.path.join(eval_path, filepath) \n","                        for filepath in os.listdir(eval_path) if filepath.endswith(\".wav\") ] \n","X_asv = [] \n","X_asv += speaker_sample_paths\n","X_asv = X_asv[:30000]\n","label_asv = [3]*len(X_asv)\n","print( \"Found {} files\".format(len(X_asv)))\n","#_, X_eval, _, y_eval = train_test_split(X_asv, label_asv, test_size=0.03333, random_state=seed)\n","X_eval = X_asv\n","y_eval = label_asv\n","print(len(X_eval))\n","print(len(y_eval))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["# making a column of names\n","import os\n","n = len(X_eval)\n","filenames = []\n","for i in range(n):\n","    f_name, f_ext = os.path.splitext(X_eval[i])\n","    filenames.append(os.path.basename(f_name)+f_ext)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["asv_ds = DataGenerator(X_eval,[5]*len(X_eval),shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["spred_class = ensemble_predictions(model_history, asv_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["asv_df = pd.DataFrame({'audio':X_eval[:len(spred_class)],'labels':spred_class})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["asv_df.labels.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["#converting dataframe to csv\n","asv_df.to_csv('inceptionnetcv_2k_asvspoof.csv', header=False, index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# final eval"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["eval_path ='../input/spcup2022-final-dataset/final_competition_eval/final_competition_eval'\n","speaker_sample_paths = [\n","        os.path.join(eval_path, filepath)\n","        for filepath in os.listdir(eval_path)\n","        if filepath.endswith(\".wav\")\n","    ]\n","X_eval = []\n","X_eval += speaker_sample_paths\n","\n","print(\n","    \"Found {} files\".format(len(X_eval))\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["# making a column of names\n","import os\n","n = len(X_eval)\n","filenames = []\n","for i in range(n):\n","    f_name, f_ext = os.path.splitext(X_eval[i])\n","    filenames.append(os.path.basename(f_name)+f_ext)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["libri_ds = DataGenerator(X_eval,[0]*len(X_eval),shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["spred_class = ensemble_predictions(model_history, libri_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["libri_df = pd.DataFrame({'audio':X_eval[:len(spred_class)],'labels':spred_class})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["libri_df.labels.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":["#converting dataframe to csv\n","libri_df.to_csv('inceptionnetcv_2k_final_eval.csv', header=False, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.9.6 ('vip_tf_gpu')' requires ipykernel package.\n","Run the following command to install 'ipykernel' into the Python environment. \n","Command: 'conda install -n vip_tf_gpu ipykernel --update-deps --force-reinstall'"]}],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":4}
